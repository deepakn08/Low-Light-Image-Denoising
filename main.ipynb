{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1Qcjo2H21RRu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model,load_model,model_from_json\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose,GlobalAveragePooling2D, AveragePooling2D, MaxPool2D, UpSampling2D,BatchNormalization, Activation, ReLU, Flatten, Dense, Input\n",
        "from tensorflow.keras.layers import Add, Multiply, Concatenate, Softmax,Reshape,Dropout\n",
        "from tensorflow.keras import initializers, regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.image import ssim\n",
        "tf.keras.backend.set_image_data_format('channels_last')\n",
        "import keras.backend as K"
      ],
      "metadata": {
        "id": "XL3G_nyJ1qjz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Serializing the Custom Library So that Json will deserialize them**"
      ],
      "metadata": {
        "id": "B6ir-MeW47JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "class Conv_block(tf.keras.layers.Layer):\n",
        "    def  __init__(self, num_filters=200, kernel_size=3,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_filters=num_filters\n",
        "        self.kernel_size=kernel_size\n",
        "        self.conv_1 = Conv2D(filters=self.num_filters, kernel_size=self.kernel_size, padding='same')\n",
        "        self.conv_2 = Conv2D(filters=self.num_filters, kernel_size=self.kernel_size, padding='same')\n",
        "        self.conv_3 = Conv2D(filters=self.num_filters, kernel_size=self.kernel_size, padding='same')\n",
        "        self.conv_4 = Conv2D(filters=self.num_filters, kernel_size=self.kernel_size, padding='same')\n",
        "        self.SE     = SEBlock(filters=self.num_filters)\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'num_filters': self.num_filters,\n",
        "            'kernel_size':self.kernel_size\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def call(self, X):\n",
        "        X = self.conv_1(X)\n",
        "        X = ReLU()(X)\n",
        "\n",
        "        X = self.conv_2(X)\n",
        "        X = ReLU()(X)\n",
        "\n",
        "        X = self.conv_3(X)\n",
        "        X = ReLU()(X)\n",
        "\n",
        "        X = self.SE(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "1d8Ep2dQ1uGj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "class SEBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, reduction=16, **kwargs):\n",
        "        super(SEBlock, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.reduction = reduction\n",
        "        self.global_avg_pool = GlobalAveragePooling2D()\n",
        "        self.reshape = Reshape((1, 1, filters))\n",
        "        self.dense1 = Dense(filters // reduction, activation='relu', kernel_initializer='he_normal', use_bias=False)\n",
        "        self.dense2 = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        se = self.global_avg_pool(input_tensor)\n",
        "        se = self.reshape(se)\n",
        "        se = self.dense1(se)\n",
        "        se = self.dense2(se)\n",
        "        return Multiply()([input_tensor, se])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(SEBlock, self).get_config()\n",
        "        config.update({\n",
        "            'filters': self.filters,\n",
        "            'reduction': self.reduction\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "WYGW6jcI1y_S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "class DWT_downsampling(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, x):\n",
        "        x1 = x[:, 0::2, 0::2, :] #x(2i−1, 2j−1)\n",
        "        x2 = x[:, 1::2, 0::2, :] #x(2i, 2j-1)\n",
        "        x3 = x[:, 0::2, 1::2, :] #x(2i−1, 2j)\n",
        "        x4 = x[:, 1::2, 1::2, :] #x(2i, 2j)\n",
        "\n",
        "        x_LL = x1 + x2 + x3 + x4\n",
        "        x_LH = -x1 - x3 + x2 + x4\n",
        "        x_HL = -x1 + x3 - x2 + x4\n",
        "        x_HH = x1 - x3 - x2 + x4\n",
        "\n",
        "        return Concatenate(axis=-1)([x_LL, x_LH, x_HL, x_HH])"
      ],
      "metadata": {
        "id": "WDwC9tck11CB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "class IWT_upsampling(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, x):\n",
        "        x_LL = x[:, :, :, 0:x.shape[3]//4]\n",
        "        x_LH = x[:, :, :, x.shape[3]//4:x.shape[3]//4*2]\n",
        "        x_HL = x[:, :, :, x.shape[3]//4*2:x.shape[3]//4*3]\n",
        "        x_HH = x[:, :, :, x.shape[3]//4*3:]\n",
        "\n",
        "        x1 = (x_LL - x_LH - x_HL + x_HH)/4\n",
        "        x2 = (x_LL - x_LH + x_HL - x_HH)/4\n",
        "        x3 = (x_LL + x_LH - x_HL - x_HH)/4\n",
        "        x4 = (x_LL + x_LH + x_HL + x_HH)/4\n",
        "\n",
        "        y1 = K.stack([x1,x3], axis=2)\n",
        "        y2 = K.stack([x2,x4], axis=2)\n",
        "        shape = K.shape(x)\n",
        "        return K.reshape(K.concatenate([y1,y2], axis=-1), K.stack([shape[0], shape[1]*2, shape[2]*2, shape[3]//4]))"
      ],
      "metadata": {
        "id": "KV6BS7lB13Jh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG19(include_top=False, weights='imagenet', input_shape=(256,256,3))\n",
        "vgg.trainable = False\n",
        "def perceptual_loss(y_true, y_pred):\n",
        "    true_features=vgg(y_true)\n",
        "    pred_features=vgg(y_pred)\n",
        "    return MeanSquaredError()(true_features, pred_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EcnLb5L18zk",
        "outputId": "80c56675-ae6c-4e47-d2ea-3e7663db356f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def psnr(y_true, y_pred):\n",
        "    max_pixel = 1.0\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=max_pixel)"
      ],
      "metadata": {
        "id": "fCWDVYTg2BPp"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ssim_loss(y_true, y_pred):\n",
        "    return 1 - tf.reduce_mean(ssim(y_true, y_pred, max_val=1.0))"
      ],
      "metadata": {
        "id": "cpaAj-d42C6r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def net_loss(y_pred,y_true):\n",
        "  perceptual=perceptual_loss(y_true=y_true,y_pred=y_pred)\n",
        "  ssim=ssim_loss(y_true=y_true,y_pred=y_pred)\n",
        "  return ssim + perceptual"
      ],
      "metadata": {
        "id": "sxy0U-f52EZq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images_list=[]\n",
        "    filenames=[]\n",
        "    for filename in os.listdir(folder):\n",
        "      img = load_img(os.path.join(folder, filename),target_size=(256,256))\n",
        "      if img is not None:\n",
        "          images_list.append(np.array(img)/255.0)\n",
        "          filenames.append(filename)\n",
        "    return images_list, filenames"
      ],
      "metadata": {
        "id": "CG_ArufK2xUm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_images_to_folder(folder, images, filenames):\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    for img, filename in zip(images, filenames):\n",
        "        img = Image.fromarray((img*255).astype('uint8'))\n",
        "        img = img.resize((600,400),Image.BILINEAR)\n",
        "        img.save(os.path.join(folder, filename))"
      ],
      "metadata": {
        "id": "Sck-32N93LrT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Call this function and pass the path of the base directory and model path.**"
      ],
      "metadata": {
        "id": "0qR0XMxk2Jax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path='./test/'"
      ],
      "metadata": {
        "id": "U4Cnp-Gy_2Dn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(base_path,model_path):\n",
        "  test_path=os.path.join(base_path,'low')\n",
        "  predicted_path=os.path.join(base_path,'predicted')\n",
        "  # Load the trained model\n",
        "  model_file=joblib.load(model_path)\n",
        "  model=tf.keras.models.model_from_json(model_file['model_json'])\n",
        "  model.set_weights(model_file['model_weights'])\n",
        "\n",
        "  #Loading the test Images\n",
        "  test_images, filenames = load_images_from_folder(test_path)\n",
        "\n",
        "  # Predicting the test images with the model\n",
        "  predicted_images = [model.predict(np.expand_dims(img, axis=0))[0] for img in test_images]\n",
        "\n",
        "  #Saving the Predicted Images\n",
        "  save_images_to_folder(predicted_path, predicted_images, filenames)\n",
        "\n",
        "  print(f\"Saved the Predicted Image to path {predicted_path}\")"
      ],
      "metadata": {
        "id": "Fz444yGF2Hqi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(base_path,'/content/drive/MyDrive/FINAL_MODEL.joblib')"
      ],
      "metadata": {
        "id": "mmljMO7o2kK5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}